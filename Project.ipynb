{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+uT7npRwjDt+1jW1QKW6g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreejan09/Sreejan09/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVpx-1H40vv_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pollen_df = pd.read_csv(\"pollen.csv\")\n",
        "airQuality_pollenCount_df = pd.read_csv(\"Air_Quality_and_Pollen_Count.csv\")\n",
        "\n",
        "print(pollen_df.head())\n",
        "print(airQuality_pollenCount_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "372M8NTP1NvU",
        "outputId": "bd2a0d37-6a80-4f2e-bf51-27dde0fcce39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date  Ambrosia  Artemisia  Asteraceae  Alnus  Betula  Ericaceae  \\\n",
            "0  1993-01-01         0          0           0      0       0          0   \n",
            "1  1993-01-02         0          0           0      0       0          0   \n",
            "2  2001-01-07         0          0           0      0       0          0   \n",
            "3  2001-01-08         0          0           0      0       0          0   \n",
            "4  2001-01-09         0          0           0      0       0          0   \n",
            "\n",
            "   Carpinus  Castanea  Quercus  ...  Rumex  Populus  Pinaceae  Plantago  \\\n",
            "0         0         0        0  ...      0        0         0         0   \n",
            "1         0         0        0  ...      0        0         0         0   \n",
            "2         0         0        0  ...      0        0         0         0   \n",
            "3         0         0        0  ...      0        0         0         0   \n",
            "4         0         0        0  ...      0        0         0         0   \n",
            "\n",
            "   Platanus  Salix  Cyperaceae  Filipendula  Sambucus  Tilia  \n",
            "0         0      0           0            0         0      0  \n",
            "1         0      0           0            0         0      0  \n",
            "2         0      0           0            0         0      0  \n",
            "3         0      0           0            0         0      0  \n",
            "4         0      0           0            0         0      0  \n",
            "\n",
            "[5 rows x 34 columns]\n",
            "   OBJECTID   AQI  Category ResponsiblePollutant  PollenCount PollenType  \\\n",
            "0         1  74.0  Moderate           Ozone 8-hr          3.0      Grass   \n",
            "1         2  64.0  Moderate           Ozone 8-hr          4.0      Grass   \n",
            "2         3  55.0  Moderate                PM2.5          3.0      Grass   \n",
            "3         4  57.0  Moderate                PM2.5          4.0      Grass   \n",
            "4         5  54.0  Moderate                PM2.5          3.0      Grass   \n",
            "\n",
            "  PollenDescription          ReportDateTime  \n",
            "0           Ragweed  2016/07/23 05:00:00+00  \n",
            "1           Ragweed  2016/07/22 05:00:00+00  \n",
            "2            Slight  2016/07/21 05:00:00+00  \n",
            "3            Slight  2016/07/20 05:00:00+00  \n",
            "4            Slight  2016/07/19 05:00:00+00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "air_quality_df = pd.read_csv('Air_Quality_and_Pollen_Count.csv')\n",
        "pollen_df = pd.read_csv('pollen.csv')\n",
        "\n",
        "# 1. Handling Missing Values\n",
        "\n",
        "# For air_quality_and_pollen_count.csv\n",
        "# Option 1: Drop rows with missing values\n",
        "air_quality_df_cleaned = air_quality_df.dropna()\n",
        "\n",
        "# Option 2: Impute missing values (Example: filling with mean)\n",
        "# air_quality_df_cleaned = air_quality_df.fillna(air_quality_df.mean())\n",
        "\n",
        "# For pollen.df (handling missing/zero values)\n",
        "# Let's check the columns with zero values\n",
        "zero_columns = pollen_df.columns[(pollen_df == 0).all()]\n",
        "\n",
        "# Remove columns that are mostly empty or have only zero values\n",
        "pollen_df_cleaned = pollen_df.drop(zero_columns, axis=1)\n",
        "\n",
        "# 2. Removing Duplicate Records\n",
        "# Check and remove duplicate rows in both datasets\n",
        "air_quality_df_cleaned = air_quality_df_cleaned.drop_duplicates()\n",
        "pollen_df_cleaned = pollen_df_cleaned.drop_duplicates()\n",
        "\n",
        "# 3. Standardizing Date Formats\n",
        "# If your datasets contain date columns, ensure they are in a consistent format\n",
        "\n",
        "# Example: converting 'date' column to a standard datetime format\n",
        "# Replace 'Report DateTime' with your actual date column name\n",
        "if 'Report DateTime' in air_quality_df_cleaned.columns:\n",
        "    air_quality_df_cleaned['Report DateTime'] = pd.to_datetime(air_quality_df_cleaned['Report DateTime'])\n",
        "\n",
        "# Similarly, if pollen.df has a date column, apply the same transformation\n",
        "if 'Date' in pollen_df_cleaned.columns:\n",
        "    pollen_df_cleaned['Date'] = pd.to_datetime(pollen_df_cleaned['Date'])\n",
        "\n",
        "# 4. Removing Columns with Zero Variance\n",
        "# Drop columns that have the same value for all rows (near-zero variance)\n",
        "air_quality_df_cleaned = air_quality_df_cleaned.loc[:, air_quality_df_cleaned.apply(pd.Series.nunique) != 1]\n",
        "pollen_df_cleaned = pollen_df_cleaned.loc[:, pollen_df_cleaned.apply(pd.Series.nunique) != 1]\n",
        "\n",
        "# Final cleaned datasets\n",
        "print(\"Air Quality Dataset:\")\n",
        "print(air_quality_df_cleaned.head())\n",
        "\n",
        "print(\"\\nPollen Dataset:\")\n",
        "print(pollen_df_cleaned.head())\n",
        "\n",
        "# Save the cleaned datasets to new CSV files\n",
        "air_quality_df_cleaned.to_csv('cleaned_air_quality_and_pollen_count.csv', index=False)\n",
        "pollen_df_cleaned.to_csv('cleaned_pollen_df.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0js8-dzT1kus",
        "outputId": "f5ebe9a7-3a2a-45fa-f6e5-704de42d2082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Air Quality Dataset:\n",
            "   OBJECTID   AQI  Category ResponsiblePollutant  PollenCount PollenType  \\\n",
            "0         1  74.0  Moderate           Ozone 8-hr          3.0      Grass   \n",
            "1         2  64.0  Moderate           Ozone 8-hr          4.0      Grass   \n",
            "2         3  55.0  Moderate                PM2.5          3.0      Grass   \n",
            "3         4  57.0  Moderate                PM2.5          4.0      Grass   \n",
            "4         5  54.0  Moderate                PM2.5          3.0      Grass   \n",
            "\n",
            "  PollenDescription          ReportDateTime  \n",
            "0           Ragweed  2016/07/23 05:00:00+00  \n",
            "1           Ragweed  2016/07/22 05:00:00+00  \n",
            "2            Slight  2016/07/21 05:00:00+00  \n",
            "3            Slight  2016/07/20 05:00:00+00  \n",
            "4            Slight  2016/07/19 05:00:00+00  \n",
            "\n",
            "Pollen Dataset:\n",
            "        Date  Ambrosia  Artemisia  Asteraceae  Alnus  Betula  Ericaceae  \\\n",
            "0 1993-01-01         0          0           0      0       0          0   \n",
            "1 1993-01-02         0          0           0      0       0          0   \n",
            "2 2001-01-07         0          0           0      0       0          0   \n",
            "3 2001-01-08         0          0           0      0       0          0   \n",
            "4 2001-01-09         0          0           0      0       0          0   \n",
            "\n",
            "   Carpinus  Castanea  Quercus  ...  Rumex  Populus  Pinaceae  Plantago  \\\n",
            "0         0         0        0  ...      0        0         0         0   \n",
            "1         0         0        0  ...      0        0         0         0   \n",
            "2         0         0        0  ...      0        0         0         0   \n",
            "3         0         0        0  ...      0        0         0         0   \n",
            "4         0         0        0  ...      0        0         0         0   \n",
            "\n",
            "   Platanus  Salix  Cyperaceae  Filipendula  Sambucus  Tilia  \n",
            "0         0      0           0            0         0      0  \n",
            "1         0      0           0            0         0      0  \n",
            "2         0      0           0            0         0      0  \n",
            "3         0      0           0            0         0      0  \n",
            "4         0      0           0            0         0      0  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pollen_df_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu6j_LUh4emh",
        "outputId": "626b1bb1-d8d3-4863-b593-03b0ba5a20bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7784"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(air_quality_df_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4_-mLqK5lfI",
        "outputId": "169be58c-a68c-488c-f003-7df1e1126fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4558"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Load the cleaned datasets again\n",
        "air_quality_df = pd.read_csv('cleaned_air_quality_and_pollen_count.csv')\n",
        "pollen_df = pd.read_csv('cleaned_pollen_df.csv')\n",
        "\n",
        "# 1. Identify Categorical Columns\n",
        "# Assume 'Category' in air quality data and 'Pollen Type' in pollen data are categorical\n",
        "categorical_columns_air_quality = air_quality_df.select_dtypes(include=['object']).columns\n",
        "categorical_columns_pollen = pollen_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 2. Handling Missing Values in Categorical Columns (if any)\n",
        "# Fill missing categorical values with 'Unknown'\n",
        "air_quality_df[categorical_columns_air_quality] = air_quality_df[categorical_columns_air_quality].fillna('Unknown')\n",
        "pollen_df[categorical_columns_pollen] = pollen_df[categorical_columns_pollen].fillna('Unknown')\n",
        "\n",
        "# 3. Apply Encoding\n",
        "# One-Hot Encoding for the 'Category' column in air_quality_df\n",
        "air_quality_df = pd.get_dummies(air_quality_df, columns=categorical_columns_air_quality, drop_first=True)\n",
        "\n",
        "# One-Hot Encoding for the 'Pollen Type' in pollen_df\n",
        "pollen_df = pd.get_dummies(pollen_df, columns=categorical_columns_pollen, drop_first=True)\n",
        "\n",
        "# Check the result after encoding\n",
        "print(\"Air Quality Data after Categorical Encoding:\")\n",
        "print(air_quality_df.head())\n",
        "\n",
        "print(\"\\nPollen Data after Categorical Encoding:\")\n",
        "print(pollen_df.head())\n",
        "\n",
        "# Save the preprocessed datasets again\n",
        "air_quality_df.to_csv('preprocessed_air_quality_and_pollen_count.csv', index=False)\n",
        "pollen_df.to_csv('preprocessed_pollen_df.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N41DaqI5oiQ",
        "outputId": "7d45926c-ccc2-4e0d-cf1e-a85eb14be9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Air Quality Data after Categorical Encoding:\n",
            "   OBJECTID   AQI  PollenCount  Category_Moderate  Category_SLIGHT  \\\n",
            "0         1  74.0          3.0               True            False   \n",
            "1         2  64.0          4.0               True            False   \n",
            "2         3  55.0          3.0               True            False   \n",
            "3         4  57.0          4.0               True            False   \n",
            "4         5  54.0          3.0               True            False   \n",
            "\n",
            "   Category_Unhealthy  Category_Unhealthy for Sensitive Groups  \\\n",
            "0               False                                    False   \n",
            "1               False                                    False   \n",
            "2               False                                    False   \n",
            "3               False                                    False   \n",
            "4               False                                    False   \n",
            "\n",
            "   ResponsiblePollutant_Oz  ResponsiblePollutant_Ozone 1-hr  \\\n",
            "0                    False                            False   \n",
            "1                    False                            False   \n",
            "2                    False                            False   \n",
            "3                    False                            False   \n",
            "4                    False                            False   \n",
            "\n",
            "   ResponsiblePollutant_Ozone 8-hr  ...  \\\n",
            "0                             True  ...   \n",
            "1                             True  ...   \n",
            "2                            False  ...   \n",
            "3                            False  ...   \n",
            "4                            False  ...   \n",
            "\n",
            "   ReportDateTime_2024/08/25 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/08/26 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/08/27 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/08/28 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/08/29 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/08/30 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/09/01 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/09/03 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/09/04 05:00:00+00  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   ReportDateTime_2024/09/05 05:00:00+00  \n",
            "0                                  False  \n",
            "1                                  False  \n",
            "2                                  False  \n",
            "3                                  False  \n",
            "4                                  False  \n",
            "\n",
            "[5 rows x 4571 columns]\n",
            "\n",
            "Pollen Data after Categorical Encoding:\n",
            "   Ambrosia  Artemisia  Asteraceae  Alnus  Betula  Ericaceae  Carpinus  \\\n",
            "0         0          0           0      0       0          0         0   \n",
            "1         0          0           0      0       0          0         0   \n",
            "2         0          0           0      0       0          0         0   \n",
            "3         0          0           0      0       0          0         0   \n",
            "4         0          0           0      0       0          0         0   \n",
            "\n",
            "   Castanea  Quercus  Chenopodium  ...  Date_2018-12-22  Date_2018-12-23  \\\n",
            "0         0        0            0  ...            False            False   \n",
            "1         0        0            0  ...            False            False   \n",
            "2         0        0            0  ...            False            False   \n",
            "3         0        0            0  ...            False            False   \n",
            "4         0        0            0  ...            False            False   \n",
            "\n",
            "   Date_2018-12-24  Date_2018-12-25  Date_2018-12-26  Date_2018-12-27  \\\n",
            "0            False            False            False            False   \n",
            "1            False            False            False            False   \n",
            "2            False            False            False            False   \n",
            "3            False            False            False            False   \n",
            "4            False            False            False            False   \n",
            "\n",
            "   Date_2018-12-28  Date_2018-12-29  Date_2018-12-30  Date_2018-12-31  \n",
            "0            False            False            False            False  \n",
            "1            False            False            False            False  \n",
            "2            False            False            False            False  \n",
            "3            False            False            False            False  \n",
            "4            False            False            False            False  \n",
            "\n",
            "[5 rows x 7816 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the cleaned datasets\n",
        "air_quality_df = pd.read_csv('cleaned_air_quality_and_pollen_count.csv')\n",
        "pollen_df = pd.read_csv('cleaned_pollen_df.csv')\n",
        "\n",
        "# 1. Handling Missing Values & Duplicates (already done)\n",
        "\n",
        "# 2. Normalization (Min-Max Scaling)\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Select numerical columns for normalization (excluding categorical ones like 'Category')\n",
        "numeric_columns_air_quality = air_quality_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "numeric_columns_pollen = pollen_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Normalize air quality dataset\n",
        "air_quality_df[numeric_columns_air_quality] = scaler.fit_transform(air_quality_df[numeric_columns_air_quality])\n",
        "\n",
        "# Normalize pollen dataset\n",
        "pollen_df[numeric_columns_pollen] = scaler.fit_transform(pollen_df[numeric_columns_pollen])\n",
        "\n",
        "# 3. Feature Selection/Extraction\n",
        "\n",
        "# Option 1: Removing columns with low variance\n",
        "# Remove columns with near-zero variance (same values across most rows)\n",
        "air_quality_df = air_quality_df.loc[:, air_quality_df.apply(pd.Series.nunique) > 1]\n",
        "pollen_df = pollen_df.loc[:, pollen_df.apply(pd.Series.nunique) > 1]\n",
        "\n",
        "# Option 2: Dropping highly correlated features\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix_air_quality = air_quality_df.corr().abs()\n",
        "correlation_matrix_pollen = pollen_df.corr().abs()\n",
        "\n",
        "# Upper triangle of the correlation matrix\n",
        "upper_tri_air_quality = correlation_matrix_air_quality.where(\n",
        "    np.triu(np.ones(correlation_matrix_air_quality.shape), k=1).astype(bool)\n",
        ")\n",
        "upper_tri_pollen = correlation_matrix_pollen.where(\n",
        "    np.triu(np.ones(correlation_matrix_pollen.shape), k=1).astype(bool)\n",
        ")\n",
        "\n",
        "# Drop highly correlated features (with correlation coefficient > 0.9)\n",
        "to_drop_air_quality = [column for column in upper_tri_air_quality.columns if any(upper_tri_air_quality[column] > 0.9)]\n",
        "to_drop_pollen = [column for column in upper_tri_pollen.columns if any(upper_tri_pollen[column] > 0.9)]\n",
        "\n",
        "air_quality_df = air_quality_df.drop(to_drop_air_quality, axis=1)\n",
        "pollen_df = pollen_df.drop(to_drop_pollen, axis=1)\n",
        "\n",
        "# Final cleaned, normalized, and preprocessed datasets\n",
        "print(\"Normalized and Feature-Selected Air Quality Dataset:\")\n",
        "print(air_quality_df.head())\n",
        "\n",
        "print(\"\\nNormalized and Feature-Selected Pollen Dataset:\")\n",
        "print(pollen_df.head())\n",
        "\n",
        "# Save the preprocessed datasets\n",
        "air_quality_df.to_csv('preprocessed_air_quality_and_pollen_count.csv', index=False)\n",
        "pollen_df.to_csv('preprocessed_pollen_df.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "f2tdqxVm6df1",
        "outputId": "01db1244-067e-4f2c-a6ba-64b496e5066e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Moderate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0c0b8c301a09>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Option 2: Dropping highly correlated features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Compute the correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mcorrelation_matrix_air_quality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mair_quality_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mcorrelation_matrix_pollen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpollen_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10702\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10703\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10704\u001b[0;31m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m             \u001b[0;31m# The underlying data was copied within _interleave, so no need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m             \u001b[0;31m# to further copy if copy=True or setting na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1713\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Moderate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrF_19jX60HM",
        "outputId": "11865f9d-710c-4cf8-f7dd-4b26923eb607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the cleaned datasets\n",
        "air_quality_df = pd.read_csv('cleaned_air_quality_and_pollen_count.csv')\n",
        "pollen_df = pd.read_csv('cleaned_pollen_df.csv')\n",
        "\n",
        "# 1. Handling Missing Values & Duplicates (already done)\n",
        "\n",
        "# 2. Normalization (Min-Max Scaling)\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Select numerical columns for normalization (excluding categorical ones like 'Category')\n",
        "numeric_columns_air_quality = air_quality_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "numeric_columns_pollen = pollen_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Normalize air quality dataset\n",
        "air_quality_df[numeric_columns_air_quality] = scaler.fit_transform(air_quality_df[numeric_columns_air_quality])\n",
        "\n",
        "# Normalize pollen dataset\n",
        "pollen_df[numeric_columns_pollen] = scaler.fit_transform(pollen_df[numeric_columns_pollen])\n",
        "\n",
        "# 3. Feature Selection/Extraction\n",
        "\n",
        "# Option 1: Removing columns with low variance\n",
        "# Remove columns with near-zero variance (same values across most rows)\n",
        "air_quality_df = air_quality_df.loc[:, air_quality_df.apply(pd.Series.nunique) > 1]\n",
        "pollen_df = pollen_df.loc[:, pollen_df.apply(pd.Series.nunique) > 1]\n",
        "\n",
        "# Option 2: Dropping highly correlated features\n",
        "# Compute the correlation matrix only for numerical columns\n",
        "correlation_matrix_air_quality = air_quality_df[numeric_columns_air_quality].corr().abs()\n",
        "correlation_matrix_pollen = pollen_df[numeric_columns_pollen].corr().abs()\n",
        "\n",
        "# Upper triangle of the correlation matrix\n",
        "upper_tri_air_quality = correlation_matrix_air_quality.where(\n",
        "    np.triu(np.ones(correlation_matrix_air_quality.shape), k=1).astype(bool)\n",
        ")\n",
        "upper_tri_pollen = correlation_matrix_pollen.where(\n",
        "    np.triu(np.ones(correlation_matrix_pollen.shape), k=1).astype(bool)\n",
        ")\n",
        "\n",
        "# Drop highly correlated features (with correlation coefficient > 0.9)\n",
        "to_drop_air_quality = [column for column in upper_tri_air_quality.columns if any(upper_tri_air_quality[column] > 0.9)]\n",
        "to_drop_pollen = [column for column in upper_tri_pollen.columns if any(upper_tri_pollen[column] > 0.9)]\n",
        "\n",
        "air_quality_df = air_quality_df.drop(to_drop_air_quality, axis=1)\n",
        "pollen_df = pollen_df.drop(to_drop_pollen, axis=1)\n",
        "\n",
        "# Final cleaned, normalized, and preprocessed datasets\n",
        "print(\"Normalized and Feature-Selected Air Quality Dataset:\")\n",
        "print(air_quality_df.head())\n",
        "\n",
        "print(\"\\nNormalized and Feature-Selected Pollen Dataset:\")\n",
        "print(pollen_df.head())\n",
        "\n",
        "# Save the preprocessed datasets\n",
        "air_quality_df.to_csv('preprocessed_air_quality_and_pollen_count.csv', index=False)\n",
        "pollen_df.to_csv('preprocessed_pollen_df.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_h1jeut6-NK",
        "outputId": "445ef522-36bb-44ff-ca8d-ebaf3203062f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized and Feature-Selected Air Quality Dataset:\n",
            "   OBJECTID       AQI  Category ResponsiblePollutant  PollenCount PollenType  \\\n",
            "0  0.000000  0.486667  Moderate           Ozone 8-hr     0.002217      Grass   \n",
            "1  0.000116  0.420000  Moderate           Ozone 8-hr     0.002956      Grass   \n",
            "2  0.000232  0.360000  Moderate                PM2.5     0.002217      Grass   \n",
            "3  0.000347  0.373333  Moderate                PM2.5     0.002956      Grass   \n",
            "4  0.000463  0.353333  Moderate                PM2.5     0.002217      Grass   \n",
            "\n",
            "  PollenDescription          ReportDateTime  \n",
            "0           Ragweed  2016/07/23 05:00:00+00  \n",
            "1           Ragweed  2016/07/22 05:00:00+00  \n",
            "2            Slight  2016/07/21 05:00:00+00  \n",
            "3            Slight  2016/07/20 05:00:00+00  \n",
            "4            Slight  2016/07/19 05:00:00+00  \n",
            "\n",
            "Normalized and Feature-Selected Pollen Dataset:\n",
            "         Date  Ambrosia  Artemisia  Asteraceae  Alnus  Betula  Ericaceae  \\\n",
            "0  1993-01-01       0.0        0.0         0.0    0.0     0.0        0.0   \n",
            "1  1993-01-02       0.0        0.0         0.0    0.0     0.0        0.0   \n",
            "2  2001-01-07       0.0        0.0         0.0    0.0     0.0        0.0   \n",
            "3  2001-01-08       0.0        0.0         0.0    0.0     0.0        0.0   \n",
            "4  2001-01-09       0.0        0.0         0.0    0.0     0.0        0.0   \n",
            "\n",
            "   Carpinus  Castanea  Quercus  ...  Rumex  Populus  Pinaceae  Plantago  \\\n",
            "0       0.0       0.0      0.0  ...    0.0      0.0       0.0       0.0   \n",
            "1       0.0       0.0      0.0  ...    0.0      0.0       0.0       0.0   \n",
            "2       0.0       0.0      0.0  ...    0.0      0.0       0.0       0.0   \n",
            "3       0.0       0.0      0.0  ...    0.0      0.0       0.0       0.0   \n",
            "4       0.0       0.0      0.0  ...    0.0      0.0       0.0       0.0   \n",
            "\n",
            "   Platanus  Salix  Cyperaceae  Filipendula  Sambucus  Tilia  \n",
            "0       0.0    0.0         0.0          0.0       0.0    0.0  \n",
            "1       0.0    0.0         0.0          0.0       0.0    0.0  \n",
            "2       0.0    0.0         0.0          0.0       0.0    0.0  \n",
            "3       0.0    0.0         0.0          0.0       0.0    0.0  \n",
            "4       0.0    0.0         0.0          0.0       0.0    0.0  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(air_quality_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p8UbAGJ7IzP",
        "outputId": "2370d6bf-2cc6-473e-f81b-d29c40642ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4558"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pollen_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L7fNKUq8vc6",
        "outputId": "667d4be0-872c-4371-a6ae-7738775f58e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7784"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('cleaned_air_quality_and_pollen_count.csv')\n",
        "\n",
        "# Check for and handle missing values\n",
        "data = data.dropna()  # Dropping rows with missing values (consider imputation if needed)\n",
        "\n",
        "# Convert categorical columns to numerical using Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    data[column] = label_encoder.fit_transform(data[column])\n",
        "\n",
        "# Feature Selection: Define features and target variable\n",
        "X = data.drop('PollenCount', axis=1)  # Features\n",
        "y = data['PollenCount']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' to handle class imbalance\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Insights\n",
        "print(\"\\nFeature Importances:\")\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importances = sorted(zip(importances, feature_names), reverse=True)\n",
        "for importance, feature in feature_importances:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "# Save the trained model if needed\n",
        "import joblib\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBMXYhT485rn",
        "outputId": "dd8a0e35-4c88-4fe2-e48a-220990a1b2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "Accuracy: 0.2906\n",
            "F1 Score: 0.2859\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.35      0.45      0.40        42\n",
            "         1.0       0.32      0.34      0.33        65\n",
            "         2.0       0.29      0.24      0.26        70\n",
            "         3.0       0.35      0.35      0.35       116\n",
            "         4.0       0.28      0.27      0.28        70\n",
            "         5.0       0.23      0.25      0.24        72\n",
            "         6.0       0.36      0.35      0.35        81\n",
            "         7.0       0.27      0.24      0.26        74\n",
            "         8.0       0.43      0.43      0.43        77\n",
            "         9.0       0.27      0.41      0.33        56\n",
            "        10.0       0.32      0.31      0.32        51\n",
            "        11.0       0.24      0.18      0.21        22\n",
            "        12.0       0.20      0.25      0.22         4\n",
            "        13.0       0.00      0.00      0.00         8\n",
            "        14.0       0.00      0.00      0.00         4\n",
            "        15.0       0.50      0.33      0.40         3\n",
            "        16.0       0.33      0.43      0.38         7\n",
            "        17.0       0.00      0.00      0.00         7\n",
            "        18.0       0.00      0.00      0.00         6\n",
            "        19.0       0.00      0.00      0.00         6\n",
            "        20.0       0.00      0.00      0.00         1\n",
            "        21.0       0.00      0.00      0.00         4\n",
            "        22.0       0.00      0.00      0.00         1\n",
            "        23.0       0.25      0.33      0.29         3\n",
            "        24.0       1.00      0.50      0.67         2\n",
            "        25.0       0.00      0.00      0.00         1\n",
            "        26.0       0.00      0.00      0.00         0\n",
            "        27.0       0.00      0.00      0.00         3\n",
            "        28.0       0.00      0.00      0.00         0\n",
            "        29.0       0.00      0.00      0.00         3\n",
            "        30.0       0.00      0.00      0.00         1\n",
            "        31.0       0.00      0.00      0.00         2\n",
            "        32.0       0.00      0.00      0.00         1\n",
            "        33.0       0.00      0.00      0.00         2\n",
            "        34.0       0.00      0.00      0.00         0\n",
            "        35.0       0.00      0.00      0.00         1\n",
            "        36.0       0.00      0.00      0.00         1\n",
            "        37.0       0.00      0.00      0.00         2\n",
            "        38.0       0.00      0.00      0.00         1\n",
            "        39.0       0.00      0.00      0.00         0\n",
            "        41.0       0.00      0.00      0.00         1\n",
            "        42.0       0.00      0.00      0.00         2\n",
            "        43.0       0.00      0.00      0.00         1\n",
            "        44.0       0.00      0.00      0.00         1\n",
            "        45.0       0.00      0.00      0.00         1\n",
            "        47.0       0.00      0.00      0.00         1\n",
            "        50.0       0.00      0.00      0.00         0\n",
            "        52.0       0.00      0.00      0.00         1\n",
            "        53.0       0.00      0.00      0.00         1\n",
            "        55.0       0.00      0.00      0.00         1\n",
            "        56.0       0.00      0.00      0.00         1\n",
            "        59.0       0.00      0.00      0.00         0\n",
            "        60.0       0.00      0.00      0.00         1\n",
            "        65.0       0.00      0.00      0.00         0\n",
            "        67.0       0.00      0.00      0.00         1\n",
            "        68.0       0.00      0.00      0.00         2\n",
            "        69.0       0.00      0.00      0.00         1\n",
            "        71.0       0.00      0.00      0.00         1\n",
            "        73.0       0.00      0.00      0.00         0\n",
            "        74.0       0.00      0.00      0.00         1\n",
            "        77.0       0.00      0.00      0.00         0\n",
            "        84.0       0.00      0.00      0.00         1\n",
            "        85.0       0.00      0.00      0.00         1\n",
            "        90.0       0.00      0.00      0.00         2\n",
            "        95.0       0.00      0.00      0.00         1\n",
            "        99.0       0.00      0.00      0.00         1\n",
            "       100.0       0.00      0.00      0.00         1\n",
            "       113.0       0.00      0.00      0.00         0\n",
            "       127.0       0.00      0.00      0.00         1\n",
            "       131.0       0.00      0.00      0.00         0\n",
            "       142.0       0.00      0.00      0.00         0\n",
            "       163.0       0.00      0.00      0.00         1\n",
            "       171.0       0.00      0.00      0.00         1\n",
            "       173.0       0.00      0.00      0.00         0\n",
            "       175.0       0.00      0.00      0.00         1\n",
            "       185.0       0.00      0.00      0.00         0\n",
            "       199.0       0.00      0.00      0.00         0\n",
            "       218.0       0.00      0.00      0.00         1\n",
            "       221.0       0.00      0.00      0.00         1\n",
            "       222.0       0.00      0.00      0.00         1\n",
            "       234.0       0.00      0.00      0.00         1\n",
            "       235.0       0.00      0.00      0.00         1\n",
            "       245.0       0.00      0.00      0.00         1\n",
            "       247.0       0.00      0.00      0.00         0\n",
            "       257.0       0.00      0.00      0.00         1\n",
            "       259.0       0.00      0.00      0.00         1\n",
            "       279.0       0.00      0.00      0.00         1\n",
            "       307.0       0.00      0.00      0.00         1\n",
            "       333.0       0.00      0.00      0.00         2\n",
            "       457.0       0.00      0.00      0.00         0\n",
            "       539.0       0.00      0.00      0.00         1\n",
            "       669.0       0.00      0.00      0.00         0\n",
            "       674.0       0.00      0.00      0.00         0\n",
            "       750.0       0.00      0.00      0.00         0\n",
            "       807.0       0.00      0.00      0.00         0\n",
            "      1133.0       0.00      0.00      0.00         0\n",
            "      1353.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.29       912\n",
            "   macro avg       0.06      0.06      0.06       912\n",
            "weighted avg       0.28      0.29      0.29       912\n",
            "\n",
            "\n",
            "Feature Importances:\n",
            "ReportDateTime: 0.2854\n",
            "OBJECTID: 0.2850\n",
            "AQI: 0.2148\n",
            "PollenDescription: 0.1085\n",
            "PollenType: 0.0577\n",
            "ResponsiblePollutant: 0.0280\n",
            "Category: 0.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['PollenCount'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaQJuYZN9Rtt",
        "outputId": "8b45d99b-249e-46a8-8b37-5aa8388f3d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PollenCount\n",
            "3.0      512\n",
            "8.0      380\n",
            "1.0      378\n",
            "4.0      373\n",
            "5.0      368\n",
            "        ... \n",
            "109.0      1\n",
            "750.0      1\n",
            "410.0      1\n",
            "300.0      1\n",
            "173.0      1\n",
            "Name: count, Length: 162, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ssBlO0BW99dq",
        "outputId": "ed82b41e-76c9-428e-c449-e7bae8ac7e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 6",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-45e1aeeb0448>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    391\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 6"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62EIcMWr-CTf",
        "outputId": "7e77d46b-b702-4979-fb3d-cf4c4163b677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PollenCount\n",
            "3.0      512\n",
            "8.0      380\n",
            "1.0      378\n",
            "4.0      373\n",
            "5.0      368\n",
            "        ... \n",
            "109.0      1\n",
            "750.0      1\n",
            "410.0      1\n",
            "300.0      1\n",
            "173.0      1\n",
            "Name: count, Length: 162, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Reduce the number of neighbors\n",
        "smote = SMOTE(random_state=42, k_neighbors=2)  # Set k_neighbors to a value less than the number of samples in the minority class\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "jpwmD1Ou-VdV",
        "outputId": "e322a13a-2087-4a45-d342-351831a704d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-56a9eaa561ee>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reduce the number of neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set k_neighbors to a value less than the number of samples in the minority class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    391\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('preprocessed_air_quality_and_pollen_count.csv')\n",
        "\n",
        "# Preprocess data (example)\n",
        "data = data.dropna()  # Drop missing values if necessary\n",
        "X = data.drop('PollenCount', axis=1)  # Features\n",
        "y = data['PollenCount']  # Target variable\n",
        "\n",
        "# Encode categorical variables if needed\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "37oIoVaV-Xwa",
        "outputId": "7cb7274b-dc7a-4ab1-a20f-4238717906b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-cc6910f4e75c>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     ]:\n\u001b[0;32m--> 216\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;34mf\"Unknown label type: {y_type}. Maybe you are trying to fit a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;34m\"classifier, which expects discrete classes on a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFP8hr50-pd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}